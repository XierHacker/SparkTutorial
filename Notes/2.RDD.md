# 一.RDD概念
Spark 中的 RDD 就是**一个不可变的分布式对象集合。** 每个 RDD 都被分为多个分区,这些
分区运行在集群中的不同节点上。

**RDD 可以包含 Python、Java、Scala 中任意类型的对象,甚至可以包含用户自定义的对象。**

对数据的所有操作不外乎创建 RDD、转化已有 RDD 以及调用 RDD 操作进行求值,所以后面的内容就主要是
关于怎么创建RDD和怎么在RDD上进行操作。


# 二.创建RDD
Spark 提供了两种创建 RDD 的方式:读取外部数据集,以及在驱动器程序中对一个集合进
行并行化。
## Ⅰ.读取外部数据集
读取外部数据集的例子在上一个博客中就已经讲到了。就是从外部文件读取然后得到一个RDD.
比如上节的`file=sc.textFile(../README.md)`　就是从外部数据集创建RDD的例子。

## Ⅱ.并行化
并行化的这种方式，其实就是把程序中的一个已有的集合传给 SparkContext 的 parallelize()
方法,它让你可以在 shell 中快速创建出自己的 RDD,然后对这些 RDD 进行操作。比如下面这段代码。
```
lines = sc.parallelize(["pandas", "i like pandas"])
```
不过,需要注意的是,除了开发原型和测试时,这种方式用得并不多,毕竟这种方式需要把你的整个数据集先放在一台机器
的内存中。

**总结来说，使用的最多的还是从外部数据创建RDD的方法。**

# 三.RDD操作
转化操作和行动操作的区别在于 Spark 计算 RDD 的方式不同。虽然你可以在任何时候定
义新的 RDD， 但 Spark 只会惰性计算这些 RDD。 **它们只有第一次在一个行动操作中用到
时，才会真正计算。**

**转化操作返回的是 RDD，而行动操作返回的是其他的数据类型。**
 
## Ⅰ.转化操作
RDD 的转化操作是返回新 RDD 的操作。转化出来的 RDD 是惰性
求值的，**只有在行动操作中用到这些 RDD 时才会被计算。** 许多转化操作都是针对各个元
素的，也就是说，这些转化操作每次只会操作 RDD 中的一个元素。不过并不是所有的转
化操作都是这样的
常见的转化操作汇总:

### (1)在原RDD每个元素上面做操作返回新RDD
**map(f, preservesPartitioning=False)**

>作用:其中参数f表示传入的函数,map的作用就是在当前这个RDD的每个元素都作用一个
函数,然后把新的RDD返回. 示例:rdd.map(x => x + 1) 结果:{2, 3, 4, 4}


**flatMap()**
>将函数应用于 RDD 中的每个元素，将返回的迭代器的所有内容构成新的 RDD。通常用来切
分单词 示例:rdd.flatMap(x => x.to(3)) {1, 2, 3, 2, 3, 3, 3}

**filter()**
>返回一个由通过传给 filter()的函数的元素组成的 RDD 示例rdd.filter(x => x != 1) {2, 3, 3}

**distinct()**
>去重  示例:rdd.distinct() {1, 2, 3}

**sample(withReplacement, fraction, [seed])**
>对 RDD 采样，以及是否替换 rdd.sample(false, 0.5) 非确定的


### (2)类集合操作
**union()**
> 生成一个包含两个 RDD 中所有元素的 RDD.示例rdd.union(other) 结果:{1, 2, 3, 3, 4, 5}

**intersection()**
>求两个RDD共同的元素的RDD  示例rdd.intersection(other) 结果:{3}

**subtract()**
>移除一个 RDD 中的内容（例如移除训练数据） rdd.subtract(other) {1, 2}

**cartesian()**
>与另一个 RDD 的笛卡儿积 rdd.cartesian(other) {(1, 3), (1, 4), ...(3, 5)}

最简单的集合操作是 union(other)，它会返回一个包含两个 RDD 中所有元素的 RDD。这
在很多用例下都很有用， 比如处理来自多个数据源的日志文件。与数学中的 union() 操作
不同的是，如果输入的 RDD 中有重复数据， Spark 的 union() 操作也会包含这些重复数据
（如有必要，我们可以通过 distinct() 实现相同的效果）。

Spark 还提供了 intersection(other) 方法，只返回两个 RDD 中都有的元素。 intersection()
在运行时也会去掉所有重复的元素（单个 RDD 内的重复元素也会一起移除）。尽管
intersection() 与 union() 的概念相似， intersection() 的性能却要差很多，因为它需要
通过网络混洗数据来发现共有的元素。

有时我们需要移除一些数据。 subtract(other) 函数接收另一个 RDD 作为参数，返回
一个由只存在于第一个 RDD 中而不存在于第二个 RDD 中的所有元素组成的 RDD。和
intersection() 一样，它也需要数据混洗。

我们也可以计算两个 RDD 的笛卡儿积，如图 3-5 所示。 cartesian(other) 转化操作会返回
所有可能的 (a, b) 对，其中 a 是源 RDD 中的元素，而 b 则来自另一个 RDD。笛卡儿积在
我们希望考虑所有可能的组合的相似度时比较有用， 比如计算各用户对各种产品的预期兴
趣程度。我们也可以求一个 RDD 与其自身的笛卡儿积，这可以用于求用户相似度的应用
中。不过要特别注意的是，求大规模 RDD 的笛卡儿积开销巨大。

## 2.行动操作
首先说一个常用的几个操作,因为很多例子都会用到.怕到时候弄不明白,所以先列在这里.

**collect()**
>作用是把RDD中的所有元素作为一个列表返回.(所以,要是RDD中元素暴多的话,就别用这个了.)

>把数据返回驱动器程序中最简单、 最常见的操作是 collect()，它会将整个 RDD 的内容返
回。 collect() 通常在单元测试中使用，因为此时 RDD 的整个内容不会很大，可以放在内
存中。使用 collect() 使得 RDD 的值与预期结果之间的对比变得很容易。由于需要将数据
复制到驱动器进程中， collect() 要求所有数据都必须能一同放入单台机器的内存中。

**count()**
>作用:返回RDD中的元素个数

**countByValue()**
>作用:返回各元素在 RDD 中出现的次数

**take(num)**
>作用:从 RDD 中返回 num 个元素

**takeOrdered(num)(ordering)**
>从 RDD 中按照提供的顺序返回最前面的 num 个元素

**takeSample(withReplacement, num, [seed])**
>从 RDD 中返回任意一些元素 rdd.takeSample(false, 1) 非确定的

上面这些是比较简单的行动操作,接下来就是有一些重要的行动操作了.
**reduce(func)**
>并 行 整 合 RDD 中 所 有 数 据（例如 sum）示例:rdd.reduce((x, y) => x + y) 9

**fold(zero)(func)**
>和 reduce() 一 样， 但 是 需 要提供初始值,示例:rdd.fold(0)((x, y) => x + y) 9

**aggregate(zeroValue)(seqOp, combOp)**
>和 reduce() 相 似， 但 是 通 常返回不同类型的函数  示例:rdd.aggregate((0, 0))
((x, y) =>
(x._1 + y, x._2 + 1),
(x, y) =>
(x._1 + y._1, x._2 + y._2))
(9,4)

**foreach(func)** 
>作用:对 RDD 中的每个元素使用给定的函数 示例:rdd.foreach(func)

## 4.向spark传递函数
## .持久化


# 四.常见任务实战